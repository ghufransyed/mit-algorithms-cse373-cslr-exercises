2.1-1
31 41 59 26 41 58 ->
31
31 41
31 41 59
31 41 59 26
31 41 59 59
31 41 41 59
31 31 41 59
26 31 41 59
26 31 41 59 41
26 31 41 59 59
26 31 41 41 59
26 31 41 41 59 58
26 31 41 41 59 59
26 31 41 41 58 59


2.1-2
see file in 01_ch directory

2.1-3
result <- NIL
for i <- 0 to A.length -1
    if A[i] = v
        result <- i
        return result
return result

Proof:
Initialization:
before the loop, result is NIL (the default return value)

Maintenance:
if A[i] = v, then result is assigned value of i and this is returned 
immediately
if A[i] != v, then result = NIL at the end of the loop

Termination:
When the loop terminates (when i = A.length - 1), result is returned, 
and the value of result is NIL if A[i] != v for all i

2.1-4
Input: Two n-element arrays, A and B, where each element is 0 or 1
Output: An (n+1)-element array C that contains the sum of the binary
numbers in A and B.

carry <- 0
result <- 0
C = [n+1]
for i <- n to 1
    result <- A[i] + B[i] + carry
    if result == 0
        C[i + 1] <- 0
    if result == 1
        C[i + 1] <- 1
    if result == 2
        C[i + 1] <- 0
        carry <- 1
    if result == 3
        C[i + 1] <- 1
        carry <- 1
if carry == 1
    C[i] <- 1
return result

2.2-1
n^3/1000 - 100n^2 - 100n + 3 is 
theta(n^3)

2.2-2
Selection sort
Write pseudocode for this algorithm, which is known as selection sort.

Input: Array containing n integers a_1,a_2...a_n
Output: Array containing a permutation of A, with
a'_1..a'_n $ a'_1 < a'_2 < .. < a'_n

min_value <- A[1]
for i <- 1 to n-1
    for j <- 2 to n
        if A[j] < min_value
            min_value <- A[j]
    A[i] = min_value


What loop invariant does this algorithm maintain?
Why does it need to run for only the first n^1 elements,
rather than for all n elements?

loop invariant: A[1..i] contains i elements, which are monotonically
increasing (sorted)

Initialization:
A[1..i] = A[1]
Thus A[1] is sorted (trivially)

Maintenance:
Before i is incremented, A[1..i] is sorted and contains the i smallest
elements from A. After i is incremented,
The inner loop iterates through from A[i+1] to A[n], on on exit, 
min_value contains the smallest value in A[i+1] to A[n]
A[i] is assigned the value of min_value, at which point A[i] is again
sorted and containing the i smallest elements of A

Termination
The out loop terminates when i = n-1
A[1..(n-1)] contains the n-1 smallest elements in A, and is sorted
A[n] therefore must contain the largest element of A
 A[1..n] is therefore sorted.

Give the best-case and worst-case running times of selection sort in â€š-notation.
Best-case: already sorted, theta(n^2)
Worst-case: reverse sorted, theta(n^2)

2.2-3
consider linear search algorithm:
Average-case: n/2 elements need to be checked if uniform distribution
= theta(n)
we ignore constant factors, such as the 1/2 that n is multiplied for
in the average case
Worst-case: n elements need to be checked (if target not in array)
= theta(n)

2.2-4
We can explicitly test for the best-case scenario, and return
the correct value, giving constant time i.e. we can cheat :)

2.3-1
3 41 52 26 38 57 9 49 ->
(3 41) (26 52) (38 57) (9 49) ->
(3 26 41 52) (9 38 49 57) ->
(3 9 26 38 41 49 52 57)

2.3-2
see merge-sort project in 02_ch

2.3-3
Use mathematic induction to show that when n is an exact power
of 2, the solution of the following recurrence is T(n) = n lg n

T(n) = 2 if n=2,
T(n) = 2T(n/2) + n if n = 2^k, for k>1

Let P(k) = T(2^k)

Base case:
P(1) = 2 = 2 lg 2 = 2^1 lg 2^1

Iterative case:
Assume that T(n) = nlg n
Then P(k) = T(2^k) = 2^k lg 2^k

P(k+1) = T (2^(k+1)) = 2T(2^(k+1)/2) + 2^(k+1)
= 2T(2^k) + 2^(k+1)
= 2 (2^k lg 2^k) + 2^(k+1)
= 2^(k+1) lg 2^k + 2^(k+1)
= 2^(k+1)(lg 2^k + 1)
= 2^(k+1)(lg 2^k + lg 2)
= 2^(k+1)(k lg 2 + lg 2)
= 2^(k+1)(k+1)(lg 2)
= 2^(k+1)(lg 2^(k+1))
QED

2.3-4

let T(n) represent the running time of the procedure
T(1) = Theta(1)
T(n) = C(n-1) + T(n-1)

see link below for info on how to do this:
http://faculty.simpson.edu/lydia.sinapova/www/cmsc250/LN250_Weiss/L14-RecRel.htm


2.3-5
Input: A sequence of n numbers A= <a1,a2,...,an> and a value v
Output: An index i such that v= A[i] or NIL if v does not appear in A

binary-search(A,v,p,r)
For Array A,

if (r-p > 1)
    q <- (p + r)/2
    if A[q] == v
        return q // stop with success
    left_result = binary-search(A,v,p,q)
    if (left_result is not NIL)
        return left_result // stop with success
    right_result = binary-search(A,v,q+1,r)
        return right_result // stop with success or failure
else
    if A[p] == v
        return p
    return NIL


Base case:
T(1) = O(1) = 1

Iterative:
T(n) = T(n/2) + 1
T(n/2) = T(n/4) + 1
...
T(2) = T(1) + 1

Summing the above and subtracting like terms on each side:
T(n) = T(1) + lg(n)
     = 1 + lg(n)
     = O(lg(n))

This is the worst-case scenario, where the sought element v is 
not in the array, so all elements must be searched for.

2.3-6
using a binary search in each iteration would NOT improve the 
overall worst-case running time of insertion sort to Theta(n lg n). 
The linear scan both finds the correct place to put the new value
on each iteration, and also makes room for the new value by shuffling
ALL of the values to the right of this position to make room for it.
Using the binary search would be Theta(lg n), but the subsequent
shuffling of items to the right would be Theta(n), so the overall
complexity would still be Theta(n)






